{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thesis: Training an Adapter for Cruise\n",
    "\n",
    "This notebook documents the workflow for training a YOLO-based adapter model tailored for cruise applications. The process includes dataset preparation, configuration file creation, model training, and result management."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Required Libraries\n",
    "\n",
    "In this step, we will install the necessary libraries for training and evaluation. This includes the `ultralytics` package, which provides the YOLO implementation used in this workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T17:10:21.622983Z",
     "iopub.status.busy": "2025-06-11T17:10:21.622770Z",
     "iopub.status.idle": "2025-06-11T17:11:57.198283Z",
     "shell.execute_reply": "2025-06-11T17:11:57.197430Z",
     "shell.execute_reply.started": "2025-06-11T17:10:21.622963Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install -q ultralytics\n",
    "from ultralytics import YOLO\n",
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create YAML Configuration for Training\n",
    "\n",
    "This section describes how to automatically generate a `data.yaml` configuration file required for YOLO training. The script reads class names from `classes.txt`, sets up dataset paths, and writes the configuration in YAML format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T17:11:57.199430Z",
     "iopub.status.busy": "2025-06-11T17:11:57.199105Z",
     "iopub.status.idle": "2025-06-11T17:11:57.358270Z",
     "shell.execute_reply": "2025-06-11T17:11:57.357146Z",
     "shell.execute_reply.started": "2025-06-11T17:11:57.199407Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Python function to automatically create data.yaml config file\n",
    "# 1. Reads \"classes.txt\" file to get list of class names\n",
    "# 2. Creates data dictionary with correct paths to folders, number of classes, and names of classes\n",
    "# 3. Writes data in YAML format to data.yaml\n",
    "\n",
    "import yaml\n",
    "import os\n",
    "\n",
    "def create_data_yaml(path_to_classes_txt, path_to_data_yaml):\n",
    "\n",
    "  # Read class.txt to get class names\n",
    "  if not os.path.exists(path_to_classes_txt):\n",
    "    print(f'classes.txt file not found! Please create a classes.txt labelmap and move it to {path_to_classes_txt}')\n",
    "    return\n",
    "  with open(path_to_classes_txt, 'r') as f:\n",
    "    classes = []\n",
    "    for line in f.readlines():\n",
    "      if len(line.strip()) == 0: continue\n",
    "      classes.append(line.strip())\n",
    "  number_of_classes = len(classes)\n",
    "\n",
    "  # Create data dictionary\n",
    "  data = {\n",
    "      'path': '/kaggle/input/adapter-cruise-control-dataset',\n",
    "      'train': 'train/images',\n",
    "      'val': 'valid/images',\n",
    "      'test': 'test/images',\n",
    "      'nc': number_of_classes,\n",
    "      'names': classes\n",
    "  }\n",
    "\n",
    "  # Write data to YAML file\n",
    "  with open(path_to_data_yaml, 'w') as f:\n",
    "    yaml.dump(data, f, sort_keys=False)\n",
    "  print(f'Created config file at {path_to_data_yaml}')\n",
    "\n",
    "  return\n",
    "\n",
    "# Define path to classes.txt and run function\n",
    "path_to_classes_txt = '/kaggle/input/adapter-cruise-control-dataset/classes.txt'\n",
    "path_to_data_yaml = 'data.yaml'\n",
    "\n",
    "create_data_yaml(path_to_classes_txt, path_to_data_yaml)\n",
    "\n",
    "print('\\nFile contents:\\n')\n",
    "!cat data.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Visualization\n",
    "\n",
    "This section demonstrates how to visualize the training data with bounding boxes. The code will:\n",
    "\n",
    "1. Load a random image from the training dataset\n",
    "2. Read its corresponding label file\n",
    "3. Draw bounding boxes and class labels on the image\n",
    "4. Display the annotated image using matplotlib\n",
    "\n",
    "This visualization helps verify that:\n",
    "- Images are loading correctly\n",
    "- Label files are properly formatted\n",
    "- Bounding box coordinates are accurate\n",
    "- Class IDs are valid\n",
    "\n",
    "The visualization uses:\n",
    "- OpenCV for image processing and drawing\n",
    "- Matplotlib for display\n",
    "- Green bounding boxes with class labels\n",
    "- RGB color format for proper display\n",
    "\n",
    "You can run the next cell to see a random training example with its annotations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "def visualize_random_sample(data_path, num_samples=1):\n",
    "    \"\"\"\n",
    "    Visualize random samples from the dataset with bounding boxes.\n",
    "    \n",
    "    Args:\n",
    "        data_path (str): Path to the dataset directory\n",
    "        num_samples (int): Number of random samples to visualize\n",
    "    \"\"\"\n",
    "    # Load the images and labels\n",
    "    images_path = os.path.join(data_path, 'train', 'images')\n",
    "    labels_path = os.path.join(data_path, 'train', 'labels')\n",
    "    \n",
    "    # Get list of image files\n",
    "    image_files = [f for f in os.listdir(images_path) if f.endswith(('.jpg', '.jpeg', '.png'))]\n",
    "    \n",
    "    # Select random images\n",
    "    selected_images = random.sample(image_files, min(num_samples, len(image_files)))\n",
    "    \n",
    "    for random_image in selected_images:\n",
    "        image_path = os.path.join(images_path, random_image)\n",
    "        label_path = os.path.join(labels_path, random_image.replace('.jpg', '.txt')\n",
    "                                 .replace('.jpeg', '.txt').replace('.png', '.txt'))\n",
    "        \n",
    "        # Read and display the image\n",
    "        img = cv2.imread(image_path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Read labels and draw boxes\n",
    "        if os.path.exists(label_path):\n",
    "            with open(label_path, 'r') as f:\n",
    "                lines = f.readlines()\n",
    "                \n",
    "            height, width = img.shape[:2]\n",
    "            for line in lines:\n",
    "                class_id, x_center, y_center, w, h = map(float, line.strip().split())\n",
    "                \n",
    "                # Convert normalized coordinates to pixel coordinates\n",
    "                x1 = int((x_center - w/2) * width)\n",
    "                y1 = int((y_center - h/2) * height)\n",
    "                x2 = int((x_center + w/2) * width)\n",
    "                y2 = int((y_center + h/2) * height)\n",
    "                \n",
    "                # Draw rectangle\n",
    "                cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "                \n",
    "                # Add class label\n",
    "                cv2.putText(img, f'Class {int(class_id)}', (x1, y1-10), \n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "        \n",
    "        plt.figure(figsize=(10, 8))\n",
    "        plt.imshow(img)\n",
    "        plt.title(f'Random Training Image with Bounding Boxes: {random_image}')\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "        \n",
    "        # Print image details\n",
    "        print(f'Image shape: {img.shape}')\n",
    "        print(f'Image path: {image_path}')\n",
    "        print(f'Number of objects detected: {len(lines) if os.path.exists(label_path) else 0}\\n')\n",
    "\n",
    "# Example usage\n",
    "data_path = '/kaggle/input/adapter-cruise-control-dataset'\n",
    "visualize_random_sample(data_path, num_samples=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start YOLO model training\n",
    "\n",
    "The model and training parameters are defined in the cell below.\n",
    "Please run the next cell to begin training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T17:11:57.362118Z",
     "iopub.status.busy": "2025-06-11T17:11:57.361254Z",
     "iopub.status.idle": "2025-06-11T17:12:02.112879Z",
     "shell.execute_reply": "2025-06-11T17:12:02.111892Z",
     "shell.execute_reply.started": "2025-06-11T17:11:57.362041Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# !yolo task=detect mode=train model=yolo11s.pt data=data.yaml epochs=120 imgsz=640 device=0,1 patience=10\n",
    "\n",
    "# Load pretrained model (better starting point than from scratch)\n",
    "model = YOLO(\"yolo11n.pt\")  # or \"yolov8s.pt\" for standard YOLOv8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T17:12:02.116536Z",
     "iopub.status.busy": "2025-06-11T17:12:02.116323Z",
     "iopub.status.idle": "2025-06-11T18:57:16.021529Z",
     "shell.execute_reply": "2025-06-11T18:57:16.020389Z",
     "shell.execute_reply.started": "2025-06-11T17:12:02.116518Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Train the model with optimized parameters\n",
    "model.train(\n",
    "    data=\"data.yaml\",\n",
    "    epochs=300,\n",
    "    imgsz=640,\n",
    "    batch=16,  # Adjust based on your GPU memory\n",
    "    device=[0,1],  # Use both GPUs\n",
    "    patience=30,  # Early stopping if no improvement for 30 epochs\n",
    "    optimizer='auto',  # Let YOLO choose the best optimizer\n",
    "    lr0=0.01,  # Initial learning rate\n",
    "    lrf=0.01,  # Final learning rate\n",
    "    momentum=0.937,\n",
    "    weight_decay=0.0005,\n",
    "    warmup_epochs=3.0,\n",
    "    warmup_momentum=0.8,\n",
    "    box=7.5,  # box loss gain\n",
    "    cls=0.5,  # cls loss gain\n",
    "    dfl=1.5,  # dfl loss gain\n",
    "    hsv_h=0.015,  # image HSV-Hue augmentation\n",
    "    hsv_s=0.7,  # image HSV-Saturation augmentation\n",
    "    hsv_v=0.4,  # image HSV-Value augmentation\n",
    "    degrees=0.0,  # image rotation\n",
    "    translate=0.1,  # image translation\n",
    "    scale=0.5,  # image scale\n",
    "    shear=0.0,  # image shear\n",
    "    perspective=0.0,  # image perspective\n",
    "    flipud=0.0,  # image flip up-down\n",
    "    fliplr=0.5,  # image flip left-right\n",
    "    mosaic=1.0,  # image mosaic\n",
    "    mixup=0.0,  # image mixup\n",
    "    copy_paste=0.0  # segment copy-paste\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Metrics Analysis\n",
    "\n",
    "After training, we can analyze the model's performance metrics to understand its effectiveness. The following metrics are particularly important:\n",
    "\n",
    "### Key Performance Indicators\n",
    "- **mAP (mean Average Precision)**: Overall detection accuracy\n",
    "- **Precision**: Ratio of true positives to all detections\n",
    "- **Recall**: Ratio of true positives to all ground truth objects\n",
    "- **F1-Score**: Harmonic mean of precision and recall\n",
    "\n",
    "### Training Progress\n",
    "- **Loss Curves**: Monitor training and validation loss\n",
    "- **Learning Rate**: Track learning rate adjustments\n",
    "- **Confusion Matrix**: Analyze detection errors\n",
    "\n",
    "### Model Efficiency\n",
    "- **Inference Speed**: Frames per second (FPS)\n",
    "- **Model Size**: Memory footprint\n",
    "- **FLOPs**: Computational complexity\n",
    "\n",
    "The metrics will be visualized in the next cell to help evaluate the model's performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T18:57:16.029834Z",
     "iopub.status.busy": "2025-06-11T18:57:16.029581Z",
     "iopub.status.idle": "2025-06-11T18:57:30.784323Z",
     "shell.execute_reply": "2025-06-11T18:57:30.783411Z",
     "shell.execute_reply.started": "2025-06-11T18:57:16.029814Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Run validation and get detailed metrics\n",
    "metrics = model.val()\n",
    "\n",
    "# Extract and print key performance metrics\n",
    "print(\"\\n=== Model Performance Metrics ===\")\n",
    "print(f\"mAP@0.5: {metrics.box.map50:.4f}\")\n",
    "print(f\"mAP@0.5:0.95: {metrics.box.map:.4f}\")\n",
    "print(f\"Precision: {metrics.box.precision:.4f}\")\n",
    "print(f\"Recall: {metrics.box.recall:.4f}\")\n",
    "print(f\"F1-Score: {metrics.box.f1:.4f}\")\n",
    "\n",
    "# Print per-class metrics\n",
    "print(\"\\n=== Per-Class Metrics ===\")\n",
    "for i, cls in enumerate(model.names):\n",
    "    print(f\"{cls}:\")\n",
    "    print(f\"  Precision: {metrics.box.precision_per_class[i]:.4f}\")\n",
    "    print(f\"  Recall: {metrics.box.recall_per_class[i]:.4f}\")\n",
    "    print(f\"  F1-Score: {metrics.box.f1_per_class[i]:.4f}\")\n",
    "\n",
    "# Calculate and print inference speed\n",
    "print(\"\\n=== Inference Speed ===\")\n",
    "print(f\"Average inference time: {metrics.speed['inference']:.2f} ms\")\n",
    "print(f\"FPS: {1000/metrics.speed['inference']:.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ## Test Results Analysis\n",
    "\n",
    "# ### Test Images Directory Structure\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained model\n",
    "model = YOLO('runs/detect/train/weights/best.pt')\n",
    "\n",
    "# Define test images directory\n",
    "test_dir = Path('test_images')\n",
    "if not test_dir.exists():\n",
    "    print(f\"Test directory {test_dir} not found!\")\n",
    "    exit()\n",
    "\n",
    "# Get all image files\n",
    "image_files = []\n",
    "for ext in ['*.jpg', '*.jpeg', '*.png']:\n",
    "    image_files.extend(list(test_dir.glob(ext)))\n",
    "\n",
    "# Create a figure with subplots\n",
    "n_images = len(image_files)\n",
    "n_cols = 3\n",
    "n_rows = (n_images + n_cols - 1) // n_cols\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 5*n_rows))\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Process each image\n",
    "for idx, img_path in enumerate(image_files):\n",
    "    if idx >= len(axes):\n",
    "        break\n",
    "        \n",
    "    # Read and process image\n",
    "    img = cv2.imread(str(img_path))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Run inference\n",
    "    results = model(img)\n",
    "    \n",
    "    # Get the first result (since we're processing single images)\n",
    "    result = results[0]\n",
    "    \n",
    "    # Draw boxes on the image\n",
    "    annotated_img = result.plot()\n",
    "    \n",
    "    # Display image\n",
    "    axes[idx].imshow(annotated_img)\n",
    "    axes[idx].set_title(f'Detections: {len(result.boxes)}')\n",
    "    axes[idx].axis('off')\n",
    "\n",
    "# Hide empty subplots\n",
    "for idx in range(len(image_files), len(axes)):\n",
    "    axes[idx].axis('off')\n",
    "    axes[idx].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print detection statistics\n",
    "print(\"\\n=== Detection Statistics ===\")\n",
    "total_detections = 0\n",
    "class_counts = {}\n",
    "\n",
    "for img_path in image_files:\n",
    "    results = model(img_path)\n",
    "    result = results[0]\n",
    "    \n",
    "    # Count detections per class\n",
    "    for box in result.boxes:\n",
    "        cls = int(box.cls[0])\n",
    "        cls_name = model.names[cls]\n",
    "        class_counts[cls_name] = class_counts.get(cls_name, 0) + 1\n",
    "        total_detections += 1\n",
    "\n",
    "print(f\"Total images processed: {len(image_files)}\")\n",
    "print(f\"Total detections: {total_detections}\")\n",
    "print(\"\\nDetections per class:\")\n",
    "for cls_name, count in class_counts.items():\n",
    "    print(f\"{cls_name}: {count}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copy Training Results to Save Server\n",
    "\n",
    "This section demonstrates how to securely copy the `runs` directory containing training results to a remote save server. This ensures that your experiment outputs are backed up and accessible for further analysis or sharing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T18:57:30.786286Z",
     "iopub.status.busy": "2025-06-11T18:57:30.785780Z",
     "iopub.status.idle": "2025-06-11T18:58:05.057759Z",
     "shell.execute_reply": "2025-06-11T18:58:05.056872Z",
     "shell.execute_reply.started": "2025-06-11T18:57:30.786244Z"
    },
    "scrolled": true,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install -q gdown\n",
    "!gdown 'https://drive.google.com/uc?id=1nQ0_w3uG8McFgPxt-kVS1RPW1aKpb2YS'\n",
    "!chmod 400 /kaggle/working/gcp-key\n",
    "!ssh -i /kaggle/working/gcp-key -o StrictHostKeyChecking=no trung@34.142.148.134 \"rm -rf /home/trung/runs\"\n",
    "!scp -i /kaggle/working/gcp-key -o StrictHostKeyChecking=no -r runs trung@34.142.148.134:/home/trung/\n",
    "!echo \"Done!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T18:58:05.061479Z",
     "iopub.status.busy": "2025-06-11T18:58:05.061164Z",
     "iopub.status.idle": "2025-06-11T18:58:06.342014Z",
     "shell.execute_reply": "2025-06-11T18:58:06.340920Z",
     "shell.execute_reply.started": "2025-06-11T18:58:05.061448Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!zip -r runs.zip runs"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7613729,
     "sourceId": 12131718,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
